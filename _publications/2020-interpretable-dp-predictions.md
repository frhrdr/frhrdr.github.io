---
title: "Interpretable and Differentially Private Predictions"
collection: publications
permalink: /publication/2020-interpretable-dp-predictions
excerpt: 'Interpretable predictions, where it is clear why a machine learning model has made a particular decision, can compromise privacy by revealing the characteristics of individual data points. This raises the central question addressed in this paper: Can models be interpretable without compromising privacy? For complex big data fit by correspondingly rich models, balancing privacy and explainability is particularly challenging, such that this question has remained largely unexplored. In this paper, we propose a family of simple models in the aim of approximating complex models using several locally linear maps per class to provide high classification accuracy, as well as differentially private explanations on the classification. We illustrate the usefulness of our approach on several image benchmark datasets as well as a medical dataset.'
date: 2020-04-03
venue: 'AISTATS2021'
paperurl: 'https://arxiv.org/abs/1906.02004'
citation: 'Harder, F., Bauer, M., & Park, M. (2020, April). Interpretable and differentially private predictions. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 04, pp. 4083-4090).'
---

We show that gradient-based attribution methods give less interpretable results on models trained with DP. We propose Locally Linear Maps (LLM) as a simple alternative to small neural nets which achieves a better interpretability-Privacy tradeoff. 

[Arxiv Version](https://arxiv.org/abs/1906.02004)
[AAAI Version](https://ojs.aaai.org/index.php/AAAI/article/view/5827)

Bibtex citation: 
<pre>@inproceedings{harder2020interpretable,
  title={Interpretable and differentially private predictions},
  author={Harder, Frederik and Bauer, Matthias and Park, Mijung},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={4083--4090},
  year={2020}
}
</pre>
